#### **Redis集群**

- **主从复制**

  - 主从复制配置非常简单只需要减配置文件增加一行配置就行了：replicaof 192.168.1.1 6379
  - 主从复制不足：
    - 解决了数据备份和一部分性能问题
    - 一主多从情况下，如果主服务器挂了，对外提供的服务就不可用了，单点问题没有得到解决，和mysql一样，每次都手动切换主服务器，比较费时或费力，期间服务不可用

- **Sentinel** 哨兵模式

  - ![redis-1](..\image\redis-1.png)

  - 我们会启动奇数个Sentinel服务，它本质上是一个运行在特殊模式之下的Redis,Sentinel也有发布订阅功能，哨兵上线时，会给一个通道发送消息，每个哨兵都订阅了这个通道，所以能相互感知对付的存在，从而进行监控

  - 服务原理

    - 服务下线
      - Sentinel是怎么知道master节点挂了，Sentinel默认以每秒钟1次的频率向Redis服务节点发送PING命令，Sentinel会将该服务器标记为下线（**主观下线**）
      - 但是，只有你发送master下线，并不代表master真的下线了，有可能是你自己的网络出现了问题，第一个发现master下线的Sentinel节点会继续询问其他的Sentinel节点，确认这个节点是否下线，如果多数Sentinel节点都认为master下线，master才会真正被下线（客观下线）
    - 故障转移
      - （Sentinel选举）故障转移流程的第一步就是在Sentinel集群选择一个Leader，Sentinle通过Raft算法，实现Sentinel选举
      - （Redis选举）对于所有的slave节点，一共有4个新宿影响选举结果
        - 如果与烧饼连接断开的比较久，超过了某个阈值，就直接失去了选举权
        - 如果拥有选举权，那就看谁的优先级更高，可以在配置文件中设置，数值越少优先级越高
        - 优先级相同，就看谁复制的数据越多（复制偏移量最大），选最多的那个
        - 如果复制数量也相同，就选进程id最小的那个

    - 总结
      - Sentinel会不断检查主服务器和从服务器是否正常运行
      - 如果某一个被监控的实例出现问题，Sentinel可以通过API发出通知
      - 但如果主服务器发生故障，Sentinel可以启动故障转移过程，并把服务器升级为主服务器，并发出通知
      - 配置管理，客户端连接到Sentinel,获取当前的Redis主服务器地址
      - 集群中至少包含奇数个实例（防止脑裂）

    - 不足
      - 主从切换的过程中会丢失数据，因为只有一个master
      - 只能单节点，没有结果水平扩容的问题

- **客户端Shading**

  - 通过一致性hash 来实现数据的均匀分布
  - 配置简单，不依赖其他中间件，分区逻辑可以自定义，比较灵活，但是技术客户端的方案，不饿能实现动态的服务增减，每个客户端需要自信维护分片策略

- 代理Proxy

  - **Twemproxy**
    -  比较文档可用性高
    - 出现故障不能自动转移，架构复杂，需要借助其他组件（LVS/HAProxy+Keepalived）
  - **Codis**
  - [**Redis Cluster** ](https://www.cnblogs.com/williamjie/p/11132211.html) 推荐（有特殊需求时，建议观看此连接）
    - **工作原理**：Redis 集群没有使用一致性hash, 而是引入了 哈希槽的概念。 Redis 集群有16384个哈希槽,每个key通过CRC16校验后对16384取模来决定放置哪个槽。集群的每个 节点负责一部分hash槽,举个例子,比如当前集群有3个节点,那么: 节点 A 包含 0 到 5460号哈希槽. 节点 B 包含5461到10922号哈希槽. 节点 C 包含10923到16383号哈希槽. 这种结构很容易添加或者删除节点，比如如果我想新添加个节点D，我需要从节点 A, B, C中得部分槽到 D上。如果我想移除节点A，需要将A中的槽移到B和C节点上，然后将没有任何槽的A节点从集群中移除 即可。由于从一个节点将哈希槽移动到另一个节点并不会停止服务，所以无论添加删除或者改变某个节 点的哈希槽的数量都不会造成集群不可用的状态。
    - **访问原理：**客户端访问任意节点时，对数据key按照CRC16规则进行hash运算，然后对运算结果对16383进行取作，如果余数在当前访问的节点管理的槽范围内，则直接返回对应的数据
      如果不在当前节点负责管理的槽范围内，则会告诉客户端去哪个节点获取数据，由客户端去正确的节点获取数据
    - **主从复制模型：**为了使在部分节点失败或者大部分节点无法通信的情况下集群仍然可用，所以集群使用了主从复制模型, 每个节点都会有N-1个复制品。 在上面具有A，B，C三个节点的集群，在没有复制模型的情况下，如果节点B失败了，那么整个集群就 会以为缺少5461到10922这个范围的槽而不可用。 然而如果在集群创建的时候（或者过一段时间）我们为每个节点添加一个从节点A1，B1，C1,那么整个 集群便有三个master节点和三个slave节点组成，这样在节点B失败后，集群便会选举B1为新的主节点 继续服务，整个集群便不会因为槽找不到而不可用了，不过当B和B1 都失败后，集群是不可用的。
    - **故障发现：** 
      - **主观下线**
        - 节点1定期发送ping消息给节点2 
        - 如果发送成功，代表节点2正常运行，节点2会响应PONG消息给节点1，节点1更新与节点2的最后通信时间 
        - 如果发送失败，则节点1与节点2之间的通信异常判断连接，在下一个定时任务周期时，仍然会与节点2发送ping消息 
        - 如果节点1发现与节点2最后通信时间超过node-timeout，则把节点2标识为pfail状态
      - **客观下线**
        - 某个节点接收到其他节点发送的ping消息，如果接收到的ping消息中包含了其他pfail节点，这个节点会将主观下线的消息内容添加到自身的故障列表中，故障列表中包含了当前节点接收到的每一个节点对其他节点的状态信息 
        - 当前节点把主观下线的消息内容添加到自身的故障列表之后，会尝试对故障节点进行客观下线操作
    - **故障恢复**
      - 对从节点的资格进行检查，只有检查的从节点才可以开始进行故障恢复 每个从节点检查与故障主节点的断线时间 超过cluster-node-timeout * cluster-slave-validity-factor数字，则取消资格 cluster-node-timeout默认为15秒，cluster-slave-validity-factor默认值为10 如果这两个参数都使用默认值，则每个节点都检查与故障主节点的断线时间，如果超过150秒，则这个节点就没有成为替换主节点的可能性
      - 使偏移量最大的节点具备最高优先级成为主节点的条件
      - 当前从节点取消复制变成离节点(slaveof no one) 
      - 执行cluster del slot撤销故障主节点负责的槽，并执行cluster add slot把这些槽分配给自己 
      - 向集群广播自己的pong消息，表明已经替换了故障从节点
    - 进行批量操作时，建议对key进行分组，建立子集，然后通过pipeline把命令发送到对应的node上每减少网络开销

